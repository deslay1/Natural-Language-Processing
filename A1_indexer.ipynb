{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Assignment #1: Building an inverted index"},{"metadata":{},"cell_type":"markdown","source":"## Objectives"},{"metadata":{},"cell_type":"markdown","source":"The objectives of this assignment are to:\n* Write a program that collects all the words from a set of documents\n* Build an index from the words\n* Represent a document using the Tf.Idf value\n* Write a short report of 1 to 2 pages on the assignment\n* Read a short text on an industrial system"},{"metadata":{},"cell_type":"markdown","source":"## Description"},{"metadata":{},"cell_type":"markdown","source":"### Outline"},{"metadata":{},"cell_type":"markdown","source":"Conceptually, an index consists of rows with one word per row and and the list of files and positions, where this word occurs. Such a row is called a _posting list_. You will encode the position of a word by the number of characters from the start of the file.\n<pre>\nword1: file_name pos1 pos2 pos3... file_name pos1 pos2 ...\nword2: file_name pos1 pos2 pos3... file_name pos1 pos2 ...\n...\n</pre>"},{"metadata":{},"cell_type":"markdown","source":"### Preparation"},{"metadata":{},"cell_type":"markdown","source":"<p>You will create an index for a corpus of Selma Lagerlöf's works:</p>\n<p>Download the <a href=\"https://github.com/pnugues/ilppp/raw/master/programs/corpus/Selma.zip\">Selma\n                folder</a> and uncompress it. It contains novels by <a href=\"https://sv.wikipedia.org/wiki/Selma_Lagerl%C3%B6f\">\n                Selma Lagerlöf</a>. The text of these novels was extracted\n                from <a href=\"https://litteraturbanken.se/forfattare/LagerlofS/titlar\">Lagerlöf arkivet</a> at\n                <a href=\"https://litteraturbanken.se/\">Litteraturbanken</a>.\n            </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":7,"outputs":[{"output_type":"stream","text":"/kaggle/input/selmanovels/kejsaren.txt\n/kaggle/input/selmanovels/osynliga.txt\n/kaggle/input/selmanovels/jerusalem.txt\n/kaggle/input/selmanovels/marbacka.txt\n/kaggle/input/selmanovels/nils.txt\n/kaggle/input/selmanovels/troll.txt\n/kaggle/input/selmanovels/bannlyst.txt\n/kaggle/input/selmanovels/herrgard.txt\n/kaggle/input/selmanovels/gosta.txt\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Running the Indexer"},{"metadata":{},"cell_type":"markdown","source":"Your final program will take a corpus as input (here the Selma novels) and produce an index of all the words with their positions. you should be able to run it this way:\n<pre>$ python indexer.py folder_name</pre>\nIn this lab, you will write it in a Jupyter Notebook. The conversion into a Python program is left as an optional exercise."},{"metadata":{},"cell_type":"markdown","source":"## Programming the Indexer"},{"metadata":{},"cell_type":"markdown","source":"To make programming easier, you will split this exercise into five steps:\n1. Index one file;\n2. Read the content of a folder\n3. Create a master index for all the files\n4. Use tfidf to represent the documents (novels)\n5. Compare the documents of a collection\n\nYou will use dictionaries to represent the postings."},{"metadata":{},"cell_type":"markdown","source":"### Indexing one file"},{"metadata":{},"cell_type":"markdown","source":"#### Description"},{"metadata":{},"cell_type":"markdown","source":"<p>Write a program that reads one document <tt>file_name.txt</tt> and outputs an index file:\n            <tt>file_name.idx</tt>:\n        </p>\n        <ol>\n            <li>The index file will contain all the unique words in the document,\n                where each word is associated with the list of its positions in the document.\n            </li>\n            <li>You will represent this index as a dictionary, where the keys will be the words, and\n                the values, the lists of positions\n            </li>\n            <li>As words, you will consider all the strings of letters that you will set in lower case.\n                You will not index the rest (i.e. numbers, punctuations, or symbols).\n            </li>\n            <li>To extract the words, you will use Unicode regular expressions. Do not use <tt>\\w+</tt>,\n                for instance, but the Unicode equivalent.\n            </li>\n            <li>The word positions will correspond to the number of characters from the beginning of the file.\n                (The word offset from the beginning)\n            </li>\n            <li>You will use <tt>finditer()</tt> to find the positions of the words.\n                This will return you match objects,\n                where you will get the matches and the positions with\n                the <tt>group()</tt> and <tt>start()</tt> methods.\n            </li>\n            <li>You will use the pickle package to write your dictionary in an file,\n                see <a href=\"https://wiki.python.org/moin/UsingPickle\">https://wiki.python.org/moin/UsingPickle</a>.\n            </li>\n        </ol>"},{"metadata":{},"cell_type":"markdown","source":"<p>Below is an excerpt of the index of the bannlyst text for the words <i>gjord</i>, <i>uppklarnande</i>, and\n            <i>stjärnor</i>. The data is stored in a dictionary:\n        </p>\n        <pre>\n{...\n'gjord': [8600, 183039, 220445],\n'uppklarnande': [8617],\n'stjärnor': [8641], ...\n}\n        </pre>\n        <p>The word <i>gjord</i> occurs three times in the text at positions 8600, 183039, and 220445, <i>uppklarnande</i>, once at\n            position 8617, and <i>stjärnor</i>, once at position 8641.\n        </p>"},{"metadata":{},"cell_type":"markdown","source":"#### Imports"},{"metadata":{},"cell_type":"markdown","source":"Some imports you could need. Add others as needed"},{"metadata":{"trusted":true},"cell_type":"code","source":"import regex as re\nimport pickle\nimport sys\nimport math\nimport time","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Writing a tokenizer "},{"metadata":{},"cell_type":"markdown","source":"Write a Unicode regular expression to find words defined as sequences of letters."},{"metadata":{"trusted":true},"cell_type":"code","source":"regex = '\\p{L}+'","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"re.findall(regex, 'En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa')","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"['En',\n 'gång',\n 'hade',\n 'de',\n 'på',\n 'Mårbacka',\n 'en',\n 'barnpiga',\n 'som',\n 'hette',\n 'Back',\n 'Kajsa']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Using `regex`, write a function to tokenize a text. Return their positions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize(text):\n    return re.finditer(regex, text)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokens = tokenize('En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa.')\nlist(tokens)","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"[<regex.Match object; span=(0, 2), match='En'>,\n <regex.Match object; span=(3, 7), match='gång'>,\n <regex.Match object; span=(8, 12), match='hade'>,\n <regex.Match object; span=(13, 15), match='de'>,\n <regex.Match object; span=(16, 18), match='på'>,\n <regex.Match object; span=(19, 27), match='Mårbacka'>,\n <regex.Match object; span=(28, 30), match='en'>,\n <regex.Match object; span=(31, 39), match='barnpiga'>,\n <regex.Match object; span=(41, 44), match='som'>,\n <regex.Match object; span=(45, 50), match='hette'>,\n <regex.Match object; span=(51, 55), match='Back'>,\n <regex.Match object; span=(56, 61), match='Kajsa'>]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Extracting indices"},{"metadata":{},"cell_type":"markdown","source":"Write a function to extract the indices from the list of tokens (words). Return a dictionary, where the keys will be the tokens (words), and the keys a list of positions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_to_idx(tokens):\n    dict = {}\n    for token in tokens:\n        if token.group() in dict:\n            dict[token.group()].append(token.start())\n        else:\n            dict[token.group()] = [token.start()]\n    return dict\n \n\n#   positions = []\n#    matches = re.finditer(regex, tokens)\n#    for match in matches:\n#        positions.append(match.start())\n#    return positions\n","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokens = tokenize('En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa.'.lower().strip())\ntext_to_idx(tokens)","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"{'en': [0, 28],\n 'gång': [3],\n 'hade': [8],\n 'de': [13],\n 'på': [16],\n 'mårbacka': [19],\n 'barnpiga': [31],\n 'som': [41],\n 'hette': [45],\n 'back': [51],\n 'kajsa': [56]}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Reading one file"},{"metadata":{},"cell_type":"markdown","source":"Read one file, _Mårbacka_, `marbacka.txt`, set it in lowercase, tokenize it, and index it. Call this index `idx`"},{"metadata":{"trusted":true},"cell_type":"code","source":"file = open('/kaggle/input/selmanovels/marbacka.txt', 'r', encoding='utf-8')\ntext_f = file.read().lower().strip()\nmb_tokens = tokenize(text_f)\nidx = text_to_idx(mb_tokens)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx['mårbacka']","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"[16,\n 139,\n 752,\n 1700,\n 2582,\n 3324,\n 15117,\n 15404,\n 27794,\n 42175,\n 49126,\n 50407,\n 52053,\n 60144,\n 63374,\n 64910,\n 67182,\n 67330,\n 67799,\n 67824,\n 69232,\n 71328,\n 72099,\n 74147,\n 74255,\n 74614,\n 76610,\n 76884,\n 77138,\n 77509,\n 77787,\n 77936,\n 78574,\n 80597,\n 81782,\n 82003,\n 84363,\n 84786,\n 85251,\n 89837,\n 97093,\n 98642,\n 100474,\n 105063,\n 105298,\n 105721,\n 108710,\n 109133,\n 112844,\n 113725,\n 114997,\n 115583,\n 115833,\n 116368,\n 116557,\n 121896,\n 124823,\n 126409,\n 126542,\n 128758,\n 130976,\n 131939,\n 132826,\n 136914,\n 137187,\n 137872,\n 139196,\n 140721,\n 142324,\n 146781,\n 151497,\n 154335,\n 155139,\n 155438,\n 155886,\n 156405,\n 158108,\n 159817,\n 160107,\n 161158,\n 162085,\n 165847,\n 168316,\n 168528,\n 169111,\n 170333,\n 172684,\n 182047,\n 182427,\n 186362,\n 189535,\n 190999,\n 191110,\n 193177,\n 196686,\n 202552,\n 206340,\n 207789,\n 208382,\n 209874,\n 210525,\n 217464,\n 219933,\n 221393,\n 221533,\n 221880,\n 222213,\n 224190,\n 229501,\n 229598,\n 230783,\n 231453,\n 232140,\n 234427,\n 236193,\n 236950,\n 240168,\n 241891,\n 242359,\n 242934,\n 243030,\n 244831,\n 249882,\n 251277,\n 251901,\n 256360,\n 260244,\n 261612,\n 262384,\n 263856,\n 266638,\n 269760,\n 270113,\n 270674,\n 271146,\n 271885,\n 272560,\n 273464,\n 275086,\n 275664,\n 276207,\n 277407,\n 292648,\n 299762,\n 306277,\n 307507,\n 307972,\n 308148,\n 308330,\n 308568,\n 311856,\n 317491,\n 321194,\n 321925,\n 328154,\n 328470,\n 328977,\n 330435,\n 331650,\n 337494,\n 340526,\n 348636,\n 349331,\n 350022,\n 350168,\n 350674,\n 350949,\n 351349,\n 354175,\n 354411,\n 356314,\n 356541,\n 356788,\n 357522,\n 358413,\n 359478,\n 360511,\n 362108,\n 363675,\n 364467,\n 365049,\n 366954,\n 367286,\n 367741,\n 368878,\n 369487,\n 373757,\n 377123,\n 378852,\n 379696]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Saving the index"},{"metadata":{},"cell_type":"markdown","source":"Save your index in a file so that you can reuse it. Use the pickel module."},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump( idx, open( \"idx.p\", \"wb\" ) )","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = pickle.load( open( \"idx.p\", \"rb\" ) )","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx['mårbacka']","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"[16,\n 139,\n 752,\n 1700,\n 2582,\n 3324,\n 15117,\n 15404,\n 27794,\n 42175,\n 49126,\n 50407,\n 52053,\n 60144,\n 63374,\n 64910,\n 67182,\n 67330,\n 67799,\n 67824,\n 69232,\n 71328,\n 72099,\n 74147,\n 74255,\n 74614,\n 76610,\n 76884,\n 77138,\n 77509,\n 77787,\n 77936,\n 78574,\n 80597,\n 81782,\n 82003,\n 84363,\n 84786,\n 85251,\n 89837,\n 97093,\n 98642,\n 100474,\n 105063,\n 105298,\n 105721,\n 108710,\n 109133,\n 112844,\n 113725,\n 114997,\n 115583,\n 115833,\n 116368,\n 116557,\n 121896,\n 124823,\n 126409,\n 126542,\n 128758,\n 130976,\n 131939,\n 132826,\n 136914,\n 137187,\n 137872,\n 139196,\n 140721,\n 142324,\n 146781,\n 151497,\n 154335,\n 155139,\n 155438,\n 155886,\n 156405,\n 158108,\n 159817,\n 160107,\n 161158,\n 162085,\n 165847,\n 168316,\n 168528,\n 169111,\n 170333,\n 172684,\n 182047,\n 182427,\n 186362,\n 189535,\n 190999,\n 191110,\n 193177,\n 196686,\n 202552,\n 206340,\n 207789,\n 208382,\n 209874,\n 210525,\n 217464,\n 219933,\n 221393,\n 221533,\n 221880,\n 222213,\n 224190,\n 229501,\n 229598,\n 230783,\n 231453,\n 232140,\n 234427,\n 236193,\n 236950,\n 240168,\n 241891,\n 242359,\n 242934,\n 243030,\n 244831,\n 249882,\n 251277,\n 251901,\n 256360,\n 260244,\n 261612,\n 262384,\n 263856,\n 266638,\n 269760,\n 270113,\n 270674,\n 271146,\n 271885,\n 272560,\n 273464,\n 275086,\n 275664,\n 276207,\n 277407,\n 292648,\n 299762,\n 306277,\n 307507,\n 307972,\n 308148,\n 308330,\n 308568,\n 311856,\n 317491,\n 321194,\n 321925,\n 328154,\n 328470,\n 328977,\n 330435,\n 331650,\n 337494,\n 340526,\n 348636,\n 349331,\n 350022,\n 350168,\n 350674,\n 350949,\n 351349,\n 354175,\n 354411,\n 356314,\n 356541,\n 356788,\n 357522,\n 358413,\n 359478,\n 360511,\n 362108,\n 363675,\n 364467,\n 365049,\n 366954,\n 367286,\n 367741,\n 368878,\n 369487,\n 373757,\n 377123,\n 378852,\n 379696]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Reading the content of a folder"},{"metadata":{},"cell_type":"markdown","source":"<p>Write a function that reads all the files in a folder with a specific suffix (txt). You will need the Python\n            os package,\n            see <a href=\"https://docs.python.org/3/library/os.html\">https://docs.python.org/3/library/os.html</a>. You\n            will return the file names in a list.\n        </p>"},{"metadata":{},"cell_type":"markdown","source":"You can reuse this function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_files(dir, suffix):\n    \"\"\"\n    Returns all the files in a folder ending with suffix\n    :param dir:\n    :param suffix:\n    :return: the list of file names\n    \"\"\"\n    files = []\n    for file in os.listdir(dir):\n        if file.endswith(suffix):\n            files.append(file)\n    return files","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus_files = get_files(\"/kaggle/input/selmanovels\", 'txt')\ncorpus_files","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"['kejsaren.txt',\n 'osynliga.txt',\n 'jerusalem.txt',\n 'marbacka.txt',\n 'nils.txt',\n 'troll.txt',\n 'bannlyst.txt',\n 'herrgard.txt',\n 'gosta.txt']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Creating a master index"},{"metadata":{},"cell_type":"markdown","source":"<p>Complete your program with the creation of master index, where you will associate each word\n            of the corpus with the files, where it occur and its positions. (a posting list)\n        </p>\n        <p>Below is an except of the master index with the words <i>samlar</i> and <i>ände</i>:\n        </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"{'samlar':\n            {'troll.txt': [641880, 654233],\n            'nils.txt': [51805, 118943],\n            'osynliga.txt': [399121],\n            'gosta.txt': [313784, 409998, 538165]},\n 'ände':\n            {'troll.txt': [39562, 650112],\n            'kejsaren.txt': [50171],\n            'marbacka.txt': [370324],\n            'nils.txt': [1794],\n            'osynliga.txt': [272144]}\n}","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"{'samlar': {'troll.txt': [641880, 654233],\n  'nils.txt': [51805, 118943],\n  'osynliga.txt': [399121],\n  'gosta.txt': [313784, 409998, 538165]},\n 'ände': {'troll.txt': [39562, 650112],\n  'kejsaren.txt': [50171],\n  'marbacka.txt': [370324],\n  'nils.txt': [1794],\n  'osynliga.txt': [272144]}}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The word <i>samlar</i>, for instance, occurs three times in the gosta text at positions\n            313784, 409998, and 538165."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_master_idx(dir, suffix):\n    master_dict = {}\n    for file_name in get_files(dir, suffix):\n        \n        # Read file\n        rfile = open(dir + \"/\" + file_name, 'r', encoding='utf-8')\n        file = rfile.read().lower().strip()\n        \n        # Tokenize and return dict with idx.\n        tokens = tokenize(file)\n        idx = text_to_idx(tokens)\n        \n        # Add to master idx.\n        for key in idx.keys():\n            if key in master_dict:\n                if file_name in master_dict[key]:\n                    master_dict[key][file_name].append(idx[key])\n                else:\n                    master_dict[key][file_name] = idx[key]\n            else:\n                dict = {}\n                dict[file_name] = idx[key]\n                master_dict[key] = dict\n\n    return master_dict\n\nmaster_index = get_master_idx(\"/kaggle/input/selmanovels\", 'txt')\nmaster_index['nils']","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"{'kejsaren.txt': [263335, 266581],\n 'jerusalem.txt': [171205, 324540, 324586],\n 'marbacka.txt': [347421, 365256],\n 'nils.txt': [17,\n  3629,\n  18122,\n  18159,\n  49682,\n  61218,\n  99050,\n  99446,\n  100632,\n  100850,\n  107420,\n  122516,\n  138978,\n  159346,\n  187665,\n  204863,\n  205377,\n  215613,\n  281268,\n  285357,\n  285454,\n  292483,\n  292713,\n  292980,\n  294817,\n  303588,\n  308340,\n  317519,\n  333659,\n  361086,\n  405967,\n  406139,\n  406724,\n  414324,\n  459738,\n  503209,\n  563342,\n  581222,\n  602124,\n  626011,\n  636848,\n  667690,\n  667951,\n  674565,\n  682702,\n  695641,\n  701899,\n  702256,\n  704143,\n  707989,\n  759870,\n  779155,\n  866429,\n  866532,\n  867887,\n  868874,\n  874170,\n  938003,\n  992433,\n  992805,\n  1011668,\n  1019630,\n  1019962,\n  1020373,\n  1045606,\n  1063798,\n  1064583,\n  1065559,\n  1068924,\n  1079624,\n  1079782,\n  1080261,\n  1082400,\n  1083201,\n  1083350,\n  1085516,\n  1086605,\n  1086798,\n  1091380],\n 'troll.txt': [273705]}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_index['samlar']","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"{'osynliga.txt': [399121],\n 'nils.txt': [51805, 118943],\n 'troll.txt': [641880, 654233],\n 'gosta.txt': [313784, 409998, 538165]}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_index['mårbacka']","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"{'marbacka.txt': [16,\n  139,\n  752,\n  1700,\n  2582,\n  3324,\n  15117,\n  15404,\n  27794,\n  42175,\n  49126,\n  50407,\n  52053,\n  60144,\n  63374,\n  64910,\n  67182,\n  67330,\n  67799,\n  67824,\n  69232,\n  71328,\n  72099,\n  74147,\n  74255,\n  74614,\n  76610,\n  76884,\n  77138,\n  77509,\n  77787,\n  77936,\n  78574,\n  80597,\n  81782,\n  82003,\n  84363,\n  84786,\n  85251,\n  89837,\n  97093,\n  98642,\n  100474,\n  105063,\n  105298,\n  105721,\n  108710,\n  109133,\n  112844,\n  113725,\n  114997,\n  115583,\n  115833,\n  116368,\n  116557,\n  121896,\n  124823,\n  126409,\n  126542,\n  128758,\n  130976,\n  131939,\n  132826,\n  136914,\n  137187,\n  137872,\n  139196,\n  140721,\n  142324,\n  146781,\n  151497,\n  154335,\n  155139,\n  155438,\n  155886,\n  156405,\n  158108,\n  159817,\n  160107,\n  161158,\n  162085,\n  165847,\n  168316,\n  168528,\n  169111,\n  170333,\n  172684,\n  182047,\n  182427,\n  186362,\n  189535,\n  190999,\n  191110,\n  193177,\n  196686,\n  202552,\n  206340,\n  207789,\n  208382,\n  209874,\n  210525,\n  217464,\n  219933,\n  221393,\n  221533,\n  221880,\n  222213,\n  224190,\n  229501,\n  229598,\n  230783,\n  231453,\n  232140,\n  234427,\n  236193,\n  236950,\n  240168,\n  241891,\n  242359,\n  242934,\n  243030,\n  244831,\n  249882,\n  251277,\n  251901,\n  256360,\n  260244,\n  261612,\n  262384,\n  263856,\n  266638,\n  269760,\n  270113,\n  270674,\n  271146,\n  271885,\n  272560,\n  273464,\n  275086,\n  275664,\n  276207,\n  277407,\n  292648,\n  299762,\n  306277,\n  307507,\n  307972,\n  308148,\n  308330,\n  308568,\n  311856,\n  317491,\n  321194,\n  321925,\n  328154,\n  328470,\n  328977,\n  330435,\n  331650,\n  337494,\n  340526,\n  348636,\n  349331,\n  350022,\n  350168,\n  350674,\n  350949,\n  351349,\n  354175,\n  354411,\n  356314,\n  356541,\n  356788,\n  357522,\n  358413,\n  359478,\n  360511,\n  362108,\n  363675,\n  364467,\n  365049,\n  366954,\n  367286,\n  367741,\n  368878,\n  369487,\n  373757,\n  377123,\n  378852,\n  379696],\n 'nils.txt': [991703],\n 'troll.txt': [226291, 387634, 392959]}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Save your master index in a file and read it again"},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(master_index, open( \"master_idx.p\", \"wb\" ) )\nmaster_index = pickle.load( open( \"master_idx.p\", \"rb\" ) )","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_index['samlar']","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"{'osynliga.txt': [399121],\n 'nils.txt': [51805, 118943],\n 'troll.txt': [641880, 654233],\n 'gosta.txt': [313784, 409998, 538165]}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Concordances"},{"metadata":{},"cell_type":"markdown","source":"Write a function to extract the concordances of a word within a window of `window` characters"},{"metadata":{"trusted":true},"cell_type":"code","source":"def concordance(text, indexer, corpus_files, width):\n    concordances = []\n    \n    pattern = text\n    # spaces match tabs and newlines\n    pattern = re.sub(' ', '\\\\s+', pattern)\n    # Replaces newlines with spaces in the text\n    text = re.sub('\\s+', ' ', text)\n    concordance = ('(.{{0,{width}}}{pattern}.{{0,{width}}})'\n                   .format(pattern=pattern, width=width))\n    for file_name in corpus_files:\n        rfile = open(\"/kaggle/input/selmanovels\" + \"/\" + file_name, 'r', encoding='utf-8')\n        file = rfile.read().lower().strip()\n        for match in re.finditer(concordance, file):\n            concordances.append(match.group(1))\n    return concordances","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concordance('samlar', master_index, corpus_files, 25)","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"[' till höger i kärran och samlar just ihop tömmarna, och ',\n 'som man i andra länder insamlar bär och frukter, så går ',\n ' bara, att du i all hast samlar ihop så mycket boss och ',\n 'ar stannat hemma, och nu samlar de sig för att intränga ',\n 'en örtkunnig läkare, som samlar in markens växter för at',\n 'on sålunda handlar och insamlar för de i fiendehänder fa',\n 'älper dem, och medan hon samlar och handlar för deras rä',\n 'om ligger nära borg, och samlar ihop ett litet middagssä',\n 'men hon samlar upp allt detta som glöda',\n 'därmed samlar han korten tillhopa, res']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Representing Documents with tf-idf"},{"metadata":{},"cell_type":"markdown","source":"<p>Once you have created the index, you will represent each document in your corpus as a word vector.\n            You will define the value of a word in a document with the tf-idf\n            metric. Tf will be the relative frequency of the term in the document and idf, the logarithm base 10 of the\n            inverse document\n            frequency.\n        </p>\n        <p>You have below the tf-idf values for a few words. In our example, the word <i>gås</i> has the value\n            0 in bannlyst.txt and the value 0.000101001964 in nils.txt\n        </p>\n        <pre>\ntroll.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 2.148161748868631e-06\n\tet\t 0.0\nkejsaren.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 8.08284798629935e-06\n\tet\t 8.273225429362848e-05\nmarbacka.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 7.582276564686669e-06\n\tet\t 9.70107989686256e-06\nherrgard.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 0.0\n\tet\t 0.0\nnils.txt\n\tkänna\t 0.0\n\tgås\t 0.00010100196417506702\n\tnils\t 0.00010164426900380124\n\tet\t 0.0\nosynliga.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 0.0\n\tet\t 0.0\njerusalem.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 4.968292117670952e-06\n\tet\t 0.0\nbannlyst.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 0.0\n\tet\t 0.0\ngosta.txt\n\tkänna\t 0.0\n\tgås\t 0.0\n\tnils\t 0.0\n\tet\t 0.0\n        </pre>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_files(dir):\n    files = {}\n    for file_name in corpus_files:\n        rfile = open(dir + \"/\" + file_name, 'r', encoding='utf-8')\n        file = rfile.read().lower().strip()\n        files[file_name] = file\n    return files\n        \nN = len(corpus_files)\n\ndef get_word_vec():\n    tfidf = {}\n    #tfidf = dict.fromkeys(corpus_files, 0)\n    files = read_files(\"/kaggle/input/selmanovels\")\n    \n    for document in list(files.keys()):\n        document_words = {}\n        tf = 0.0\n        idf = 0.0\n        for word in master_index.keys():\n            d = len(master_index[word].keys())\n            \n            if document in master_index[word]:\n                tf = len(master_index[word][document]) / len(files[document])\n                idf = math.log(N/d, 10)\n                document_words[word] = tf*idf\n            else:\n                document_words[word] = 0.0\n        tfidf[document] = document_words\n    \n    return tfidf\n\ntfidf = get_word_vec()","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf['troll.txt']['känna']","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"0.0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf['troll.txt']['nils']","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"3.84249211027629e-07"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Comparing Documents"},{"metadata":{},"cell_type":"markdown","source":"Using the cosine similarity, compare all the pairs of documents with their tfidf representation and present\n            your results in a matrix. You will include this matrix in your report."},{"metadata":{},"cell_type":"markdown","source":"#### Cosine similarity"},{"metadata":{},"cell_type":"markdown","source":"Write a function computing the cosine similarity between two documents"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import dot\nfrom numpy.linalg import norm\n\n\ndef cosine_similarity(doc1, doc2):\n    lv_doc1 = list(doc1.values())\n    lv_doc2 = list(doc2.values())\n    return dot(lv_doc1, lv_doc2)/(norm(lv_doc1)*norm(lv_doc2))\n","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Similarity matrix"},{"metadata":{},"cell_type":"markdown","source":"Compute the similarity matrix between the documents of the corpus"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"matrix = []\nmax_similarity = 0\nmost_sim_f1 = ''\nmost_sim_f2 = ''\nfor document_one in tfidf.keys():\n    row = []\n    for document_two in tfidf.keys():\n        if document_one != document_two:\n            sim = cosine_similarity(tfidf[document_one], tfidf[document_two])\n            if sim > max_similarity:\n                max_similarity = sim\n                most_sim_f1 = document_one\n                most_sim_f2 = document_two\n        else:\n            sim = 0\n        row.append(sim)\n            \n    matrix.append(row)\n    \nfrom pandas import DataFrame as df\nfunc = lambda x: round(x,3)\n\nmatrix = [list(map(func, i)) for i in matrix]\ndf_m = df(matrix)\ndf_m.columns = list(tfidf.keys())\ndf_m","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"   kejsaren.txt  osynliga.txt  jerusalem.txt  marbacka.txt  nils.txt  \\\n0         0.000         0.051          0.002         0.071     0.050   \n1         0.051         0.000          0.028         0.093     0.111   \n2         0.002         0.028          0.000         0.005     0.005   \n3         0.071         0.093          0.005         0.000     0.085   \n4         0.050         0.111          0.005         0.085     0.000   \n5         0.181         0.193          0.007         0.147     0.188   \n6         0.024         0.052          0.006         0.037     0.051   \n7         0.001         0.005          0.371         0.004     0.005   \n8         0.048         0.125          0.004         0.080     0.105   \n\n   troll.txt  bannlyst.txt  herrgard.txt  gosta.txt  \n0      0.181         0.024         0.001      0.048  \n1      0.193         0.052         0.005      0.125  \n2      0.007         0.006         0.371      0.004  \n3      0.147         0.037         0.004      0.080  \n4      0.188         0.051         0.005      0.105  \n5      0.000         0.089         0.004      0.196  \n6      0.089         0.000         0.001      0.049  \n7      0.004         0.001         0.000      0.003  \n8      0.196         0.049         0.003      0.000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kejsaren.txt</th>\n      <th>osynliga.txt</th>\n      <th>jerusalem.txt</th>\n      <th>marbacka.txt</th>\n      <th>nils.txt</th>\n      <th>troll.txt</th>\n      <th>bannlyst.txt</th>\n      <th>herrgard.txt</th>\n      <th>gosta.txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000</td>\n      <td>0.051</td>\n      <td>0.002</td>\n      <td>0.071</td>\n      <td>0.050</td>\n      <td>0.181</td>\n      <td>0.024</td>\n      <td>0.001</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.051</td>\n      <td>0.000</td>\n      <td>0.028</td>\n      <td>0.093</td>\n      <td>0.111</td>\n      <td>0.193</td>\n      <td>0.052</td>\n      <td>0.005</td>\n      <td>0.125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002</td>\n      <td>0.028</td>\n      <td>0.000</td>\n      <td>0.005</td>\n      <td>0.005</td>\n      <td>0.007</td>\n      <td>0.006</td>\n      <td>0.371</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.071</td>\n      <td>0.093</td>\n      <td>0.005</td>\n      <td>0.000</td>\n      <td>0.085</td>\n      <td>0.147</td>\n      <td>0.037</td>\n      <td>0.004</td>\n      <td>0.080</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.050</td>\n      <td>0.111</td>\n      <td>0.005</td>\n      <td>0.085</td>\n      <td>0.000</td>\n      <td>0.188</td>\n      <td>0.051</td>\n      <td>0.005</td>\n      <td>0.105</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.181</td>\n      <td>0.193</td>\n      <td>0.007</td>\n      <td>0.147</td>\n      <td>0.188</td>\n      <td>0.000</td>\n      <td>0.089</td>\n      <td>0.004</td>\n      <td>0.196</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.024</td>\n      <td>0.052</td>\n      <td>0.006</td>\n      <td>0.037</td>\n      <td>0.051</td>\n      <td>0.089</td>\n      <td>0.000</td>\n      <td>0.001</td>\n      <td>0.049</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.001</td>\n      <td>0.005</td>\n      <td>0.371</td>\n      <td>0.004</td>\n      <td>0.005</td>\n      <td>0.004</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.048</td>\n      <td>0.125</td>\n      <td>0.004</td>\n      <td>0.080</td>\n      <td>0.105</td>\n      <td>0.196</td>\n      <td>0.049</td>\n      <td>0.003</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Give the name of the two novels that are the most similar."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Most similar:\", most_sim_f1, most_sim_f2, \"Similarity:\", max_similarity)","execution_count":35,"outputs":[{"output_type":"stream","text":"Most similar: jerusalem.txt herrgard.txt Similarity: 0.37068942387339526\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<h2>Reading</h2>"},{"metadata":{},"cell_type":"markdown","source":"<p>Read the text:\n            <i>Challenges in Building Large-Scale Information Retrieval Systems</i>\n            about the history of\n            <a href=\"https://research.google.com/people/jeff/WSDM09-keynote.pdf\">Google indexing</a>\n            by\n            <a href=\"https://research.google.com/pubs/jeff.html\">Jeff Dean</a>.\n            In your report, tell how your index encoding is related to what Google did.\n            You must identify the slide where you have the most similar indexing technique and write the\n            slide number in your report.\n        </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}