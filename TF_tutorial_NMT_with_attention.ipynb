{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028067,
     "end_time": "2020-11-26T17:03:58.294794",
     "exception": false,
     "start_time": "2020-11-26T17:03:58.266727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Neural machine translation using attention\n",
    "\n",
    "In this notebook I am following the tensorflow tutorial that aims to build a machine translation model based on recent papers: https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "\n",
    "The tutorial uses a dataset of English and Spanish sentences.\n",
    "Here I use English and Swedish sentences. Dataset received from http://www.manythings.org/anki/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-26T17:03:58.419346Z",
     "iopub.status.busy": "2020-11-26T17:03:58.418345Z",
     "iopub.status.idle": "2020-11-26T17:04:04.754961Z",
     "shell.execute_reply": "2020-11-26T17:04:04.753397Z"
    },
    "papermill": {
     "duration": 6.432581,
     "end_time": "2020-11-26T17:04:04.755109",
     "exception": false,
     "start_time": "2020-11-26T17:03:58.322528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029482,
     "end_time": "2020-11-26T17:04:04.815207",
     "exception": false,
     "start_time": "2020-11-26T17:04:04.785725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028411,
     "end_time": "2020-11-26T17:04:04.872779",
     "exception": false,
     "start_time": "2020-11-26T17:04:04.844368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adding start and end tokens, remove special characters, create index mappings and pad sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:04.934975Z",
     "iopub.status.busy": "2020-11-26T17:04:04.932999Z",
     "iopub.status.idle": "2020-11-26T17:04:04.935670Z",
     "shell.execute_reply": "2020-11-26T17:04:04.936169Z"
    },
    "papermill": {
     "duration": 0.035357,
     "end_time": "2020-11-26T17:04:04.936290",
     "exception": false,
     "start_time": "2020-11-26T17:04:04.900933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_dataset = '../input/bilingual-swe-eng-sentence-pairs/swe.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027686,
     "end_time": "2020-11-26T17:04:04.990627",
     "exception": false,
     "start_time": "2020-11-26T17:04:04.962941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:05.053944Z",
     "iopub.status.busy": "2020-11-26T17:04:05.053194Z",
     "iopub.status.idle": "2020-11-26T17:04:05.057514Z",
     "shell.execute_reply": "2020-11-26T17:04:05.057014Z"
    },
    "papermill": {
     "duration": 0.039478,
     "end_time": "2020-11-26T17:04:05.057609",
     "exception": false,
     "start_time": "2020-11-26T17:04:05.018131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:05.123778Z",
     "iopub.status.busy": "2020-11-26T17:04:05.122808Z",
     "iopub.status.idle": "2020-11-26T17:04:05.128350Z",
     "shell.execute_reply": "2020-11-26T17:04:05.127544Z"
    },
    "papermill": {
     "duration": 0.043989,
     "end_time": "2020-11-26T17:04:05.128453",
     "exception": false,
     "start_time": "2020-11-26T17:04:05.084464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf far jag lana den har boken ? <end>'\n"
     ]
    }
   ],
   "source": [
    "# See examples\n",
    "en_sentence = u\"May I borrow this book?\"\n",
    "sv_sentence = u\"¿Får jag låna den här boken?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sv_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:05.195455Z",
     "iopub.status.busy": "2020-11-26T17:04:05.193594Z",
     "iopub.status.idle": "2020-11-26T17:04:05.196483Z",
     "shell.execute_reply": "2020-11-26T17:04:05.196976Z"
    },
    "papermill": {
     "duration": 0.039626,
     "end_time": "2020-11-26T17:04:05.197093",
     "exception": false,
     "start_time": "2020-11-26T17:04:05.157467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SWEDISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    \n",
    "    # If i < 2 because file contains other information such as author and reference. basically we use the first two tabbed elements.\n",
    "    word_pairs = [[preprocess_sentence(w) for i, w in enumerate(l.split('\\t')) if i < 2]  for l in lines[:num_examples]]\n",
    "    \n",
    "    #print(zip(zip(*word_pairs)))\n",
    "    \n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:05.264378Z",
     "iopub.status.busy": "2020-11-26T17:04:05.263472Z",
     "iopub.status.idle": "2020-11-26T17:04:06.511503Z",
     "shell.execute_reply": "2020-11-26T17:04:06.512141Z"
    },
    "papermill": {
     "duration": 1.284878,
     "end_time": "2020-11-26T17:04:06.512286",
     "exception": false,
     "start_time": "2020-11-26T17:04:05.227408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you translate from your second language into your own native language , rather than the other way around , you re less likely to make mistakes . <end>\n",
      "<start> om man oversatter fran sitt andrasprak till sitt modersmal , istallet for omvant , ar det mindre sannolikhet for att man gor fel . <end>\n"
     ]
    }
   ],
   "source": [
    "# Example of how we get bilingual sentence pairs.\n",
    "en, sv = create_dataset(path_to_dataset, None)\n",
    "print(en[-1])\n",
    "print(sv[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:06.581183Z",
     "iopub.status.busy": "2020-11-26T17:04:06.580429Z",
     "iopub.status.idle": "2020-11-26T17:04:06.583944Z",
     "shell.execute_reply": "2020-11-26T17:04:06.584387Z"
    },
    "papermill": {
     "duration": 0.041309,
     "end_time": "2020-11-26T17:04:06.584533",
     "exception": false,
     "start_time": "2020-11-26T17:04:06.543224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:06.654168Z",
     "iopub.status.busy": "2020-11-26T17:04:06.652334Z",
     "iopub.status.idle": "2020-11-26T17:04:06.654940Z",
     "shell.execute_reply": "2020-11-26T17:04:06.655454Z"
    },
    "papermill": {
     "duration": 0.040458,
     "end_time": "2020-11-26T17:04:06.655649",
     "exception": false,
     "start_time": "2020-11-26T17:04:06.615191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03393,
     "end_time": "2020-11-26T17:04:06.720770",
     "exception": false,
     "start_time": "2020-11-26T17:04:06.686840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Sometimes we only want a portion of our dataset to try it out first.\n",
    "\n",
    "Since our dataset contains a maximum of 18 655 sentences we don't need to set a limit. Google's tutorial on the spanish-english pairs has more than 100 000 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:06.799799Z",
     "iopub.status.busy": "2020-11-26T17:04:06.798623Z",
     "iopub.status.idle": "2020-11-26T17:04:09.221814Z",
     "shell.execute_reply": "2020-11-26T17:04:09.221173Z"
    },
    "papermill": {
     "duration": 2.460618,
     "end_time": "2020-11-26T17:04:09.221947",
     "exception": false,
     "start_time": "2020-11-26T17:04:06.761329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum English sentence length: 38\n",
      "Maximum Swedish sentence length: 34\n"
     ]
    }
   ],
   "source": [
    "num_examples = None\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_dataset, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "print('Maximum English sentence length: {}'.format(max_length_targ))\n",
    "print('Maximum Swedish sentence length: {}'.format(max_length_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:09.290609Z",
     "iopub.status.busy": "2020-11-26T17:04:09.289752Z",
     "iopub.status.idle": "2020-11-26T17:04:09.302348Z",
     "shell.execute_reply": "2020-11-26T17:04:09.301645Z"
    },
    "papermill": {
     "duration": 0.04887,
     "end_time": "2020-11-26T17:04:09.302502",
     "exception": false,
     "start_time": "2020-11-26T17:04:09.253632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14924 14924 3731 3731\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029491,
     "end_time": "2020-11-26T17:04:09.363245",
     "exception": false,
     "start_time": "2020-11-26T17:04:09.333754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Produce index mappings from our tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:09.431176Z",
     "iopub.status.busy": "2020-11-26T17:04:09.430388Z",
     "iopub.status.idle": "2020-11-26T17:04:09.433406Z",
     "shell.execute_reply": "2020-11-26T17:04:09.432922Z"
    },
    "papermill": {
     "duration": 0.039739,
     "end_time": "2020-11-26T17:04:09.433560",
     "exception": false,
     "start_time": "2020-11-26T17:04:09.393821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:09.501033Z",
     "iopub.status.busy": "2020-11-26T17:04:09.500142Z",
     "iopub.status.idle": "2020-11-26T17:04:09.508730Z",
     "shell.execute_reply": "2020-11-26T17:04:09.508199Z"
    },
    "papermill": {
     "duration": 0.044848,
     "end_time": "2020-11-26T17:04:09.508848",
     "exception": false,
     "start_time": "2020-11-26T17:04:09.464000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "129 ----> nagra\n",
      "153 ----> barn\n",
      "2440 ----> leker\n",
      "18 ----> i\n",
      "771 ----> parken\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "96 ----> some\n",
      "470 ----> kids\n",
      "28 ----> are\n",
      "356 ----> playing\n",
      "23 ----> in\n",
      "8 ----> the\n",
      "542 ----> park\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:10.430871Z",
     "iopub.status.busy": "2020-11-26T17:04:10.429955Z",
     "iopub.status.idle": "2020-11-26T17:04:11.952075Z",
     "shell.execute_reply": "2020-11-26T17:04:11.951134Z"
    },
    "papermill": {
     "duration": 2.412378,
     "end_time": "2020-11-26T17:04:11.952194",
     "exception": false,
     "start_time": "2020-11-26T17:04:09.539816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03208,
     "end_time": "2020-11-26T17:04:12.016956",
     "exception": false,
     "start_time": "2020-11-26T17:04:11.984876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The resulting batch shapes are in the format of (batch_size, longest_sentence_length_for_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:12.086656Z",
     "iopub.status.busy": "2020-11-26T17:04:12.085825Z",
     "iopub.status.idle": "2020-11-26T17:04:12.151170Z",
     "shell.execute_reply": "2020-11-26T17:04:12.150646Z"
    },
    "papermill": {
     "duration": 0.101659,
     "end_time": "2020-11-26T17:04:12.151294",
     "exception": false,
     "start_time": "2020-11-26T17:04:12.049635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 34]), TensorShape([64, 38]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031995,
     "end_time": "2020-11-26T17:04:12.215607",
     "exception": false,
     "start_time": "2020-11-26T17:04:12.183612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030933,
     "end_time": "2020-11-26T17:04:12.278234",
     "exception": false,
     "start_time": "2020-11-26T17:04:12.247301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "See https://www.tensorflow.org/tutorials/text/nmt_with_attention#write_the_encoder_and_decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:12.353540Z",
     "iopub.status.busy": "2020-11-26T17:04:12.352838Z",
     "iopub.status.idle": "2020-11-26T17:04:12.356512Z",
     "shell.execute_reply": "2020-11-26T17:04:12.355965Z"
    },
    "papermill": {
     "duration": 0.046395,
     "end_time": "2020-11-26T17:04:12.356615",
     "exception": false,
     "start_time": "2020-11-26T17:04:12.310220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:12.426268Z",
     "iopub.status.busy": "2020-11-26T17:04:12.425339Z",
     "iopub.status.idle": "2020-11-26T17:04:14.958178Z",
     "shell.execute_reply": "2020-11-26T17:04:14.959048Z"
    },
    "papermill": {
     "duration": 2.571098,
     "end_time": "2020-11-26T17:04:14.959221",
     "exception": false,
     "start_time": "2020-11-26T17:04:12.388123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 34, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Create encoder instance\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033458,
     "end_time": "2020-11-26T17:04:15.025221",
     "exception": false,
     "start_time": "2020-11-26T17:04:14.991763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Attention\n",
    "\n",
    "We compute the attention vectors using Bahdanau attention. See link above for reference to actual paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:15.101953Z",
     "iopub.status.busy": "2020-11-26T17:04:15.099918Z",
     "iopub.status.idle": "2020-11-26T17:04:15.102800Z",
     "shell.execute_reply": "2020-11-26T17:04:15.103267Z"
    },
    "papermill": {
     "duration": 0.046124,
     "end_time": "2020-11-26T17:04:15.103384",
     "exception": false,
     "start_time": "2020-11-26T17:04:15.057260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:15.178995Z",
     "iopub.status.busy": "2020-11-26T17:04:15.178071Z",
     "iopub.status.idle": "2020-11-26T17:04:15.845297Z",
     "shell.execute_reply": "2020-11-26T17:04:15.845842Z"
    },
    "papermill": {
     "duration": 0.709463,
     "end_time": "2020-11-26T17:04:15.845991",
     "exception": false,
     "start_time": "2020-11-26T17:04:15.136528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 34, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033321,
     "end_time": "2020-11-26T17:04:15.913210",
     "exception": false,
     "start_time": "2020-11-26T17:04:15.879889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create decoder model using attention vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:15.994294Z",
     "iopub.status.busy": "2020-11-26T17:04:15.993476Z",
     "iopub.status.idle": "2020-11-26T17:04:15.997897Z",
     "shell.execute_reply": "2020-11-26T17:04:15.997322Z"
    },
    "papermill": {
     "duration": 0.050237,
     "end_time": "2020-11-26T17:04:15.998030",
     "exception": false,
     "start_time": "2020-11-26T17:04:15.947793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:16.072425Z",
     "iopub.status.busy": "2020-11-26T17:04:16.071535Z",
     "iopub.status.idle": "2020-11-26T17:04:16.134927Z",
     "shell.execute_reply": "2020-11-26T17:04:16.135626Z"
    },
    "papermill": {
     "duration": 0.104422,
     "end_time": "2020-11-26T17:04:16.135800",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.031378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 5056)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0337,
     "end_time": "2020-11-26T17:04:16.205020",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.171320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:16.280936Z",
     "iopub.status.busy": "2020-11-26T17:04:16.280107Z",
     "iopub.status.idle": "2020-11-26T17:04:16.284604Z",
     "shell.execute_reply": "2020-11-26T17:04:16.284113Z"
    },
    "papermill": {
     "duration": 0.045288,
     "end_time": "2020-11-26T17:04:16.284708",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.239420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034131,
     "end_time": "2020-11-26T17:04:16.353264",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.319133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Good practice to use checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:16.425968Z",
     "iopub.status.busy": "2020-11-26T17:04:16.425225Z",
     "iopub.status.idle": "2020-11-26T17:04:16.429316Z",
     "shell.execute_reply": "2020-11-26T17:04:16.428863Z"
    },
    "papermill": {
     "duration": 0.042459,
     "end_time": "2020-11-26T17:04:16.429410",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.386951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033347,
     "end_time": "2020-11-26T17:04:16.497771",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.464424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "See pipeline at: https://www.tensorflow.org/tutorials/text/nmt_with_attention#training\n",
    "\n",
    "We use teacher forcing to decide next input. Basically we use the previously predicted target as next input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:16.579930Z",
     "iopub.status.busy": "2020-11-26T17:04:16.578121Z",
     "iopub.status.idle": "2020-11-26T17:04:16.580711Z",
     "shell.execute_reply": "2020-11-26T17:04:16.581174Z"
    },
    "papermill": {
     "duration": 0.04836,
     "end_time": "2020-11-26T17:04:16.581284",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.532924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:04:16.660414Z",
     "iopub.status.busy": "2020-11-26T17:04:16.659590Z",
     "iopub.status.idle": "2020-11-26T17:14:27.817084Z",
     "shell.execute_reply": "2020-11-26T17:14:27.817756Z"
    },
    "papermill": {
     "duration": 611.202091,
     "end_time": "2020-11-26T17:14:27.817927",
     "exception": false,
     "start_time": "2020-11-26T17:04:16.615836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.6375\n",
      "Epoch 1 Batch 100 Loss 0.8837\n",
      "Epoch 1 Batch 200 Loss 0.7786\n",
      "Epoch 1 Loss 0.8737\n",
      "Time taken for 1 epoch 103.57483458518982 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.6918\n",
      "Epoch 2 Batch 100 Loss 0.6487\n",
      "Epoch 2 Batch 200 Loss 0.5638\n",
      "Epoch 2 Loss 0.6471\n",
      "Time taken for 1 epoch 56.46144890785217 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.5882\n",
      "Epoch 3 Batch 100 Loss 0.4558\n",
      "Epoch 3 Batch 200 Loss 0.4827\n",
      "Epoch 3 Loss 0.4860\n",
      "Time taken for 1 epoch 56.142348527908325 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.3660\n",
      "Epoch 4 Batch 100 Loss 0.3819\n",
      "Epoch 4 Batch 200 Loss 0.3492\n",
      "Epoch 4 Loss 0.3578\n",
      "Time taken for 1 epoch 56.535074949264526 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2737\n",
      "Epoch 5 Batch 100 Loss 0.2302\n",
      "Epoch 5 Batch 200 Loss 0.2370\n",
      "Epoch 5 Loss 0.2620\n",
      "Time taken for 1 epoch 56.28939175605774 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1697\n",
      "Epoch 6 Batch 100 Loss 0.1970\n",
      "Epoch 6 Batch 200 Loss 0.1763\n",
      "Epoch 6 Loss 0.1928\n",
      "Time taken for 1 epoch 56.5539116859436 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1512\n",
      "Epoch 7 Batch 100 Loss 0.1203\n",
      "Epoch 7 Batch 200 Loss 0.1200\n",
      "Epoch 7 Loss 0.1415\n",
      "Time taken for 1 epoch 56.16203022003174 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1038\n",
      "Epoch 8 Batch 100 Loss 0.1059\n",
      "Epoch 8 Batch 200 Loss 0.2767\n",
      "Epoch 8 Loss 0.1169\n",
      "Time taken for 1 epoch 56.44256019592285 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1017\n",
      "Epoch 9 Batch 100 Loss 0.0845\n",
      "Epoch 9 Batch 200 Loss 0.1327\n",
      "Epoch 9 Loss 0.0953\n",
      "Time taken for 1 epoch 56.32991433143616 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0527\n",
      "Epoch 10 Batch 100 Loss 0.0629\n",
      "Epoch 10 Batch 200 Loss 0.0582\n",
      "Epoch 10 Loss 0.0667\n",
      "Time taken for 1 epoch 56.610830783843994 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048533,
     "end_time": "2020-11-26T17:14:27.915440",
     "exception": false,
     "start_time": "2020-11-26T17:14:27.866907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:14:28.031631Z",
     "iopub.status.busy": "2020-11-26T17:14:28.029530Z",
     "iopub.status.idle": "2020-11-26T17:14:28.032436Z",
     "shell.execute_reply": "2020-11-26T17:14:28.033034Z"
    },
    "papermill": {
     "duration": 0.068036,
     "end_time": "2020-11-26T17:14:28.033187",
     "exception": false,
     "start_time": "2020-11-26T17:14:27.965151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:14:28.153004Z",
     "iopub.status.busy": "2020-11-26T17:14:28.152165Z",
     "iopub.status.idle": "2020-11-26T17:14:28.156828Z",
     "shell.execute_reply": "2020-11-26T17:14:28.156290Z"
    },
    "papermill": {
     "duration": 0.067901,
     "end_time": "2020-11-26T17:14:28.156951",
     "exception": false,
     "start_time": "2020-11-26T17:14:28.089050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:14:28.271112Z",
     "iopub.status.busy": "2020-11-26T17:14:28.269020Z",
     "iopub.status.idle": "2020-11-26T17:14:28.271906Z",
     "shell.execute_reply": "2020-11-26T17:14:28.272442Z"
    },
    "papermill": {
     "duration": 0.063993,
     "end_time": "2020-11-26T17:14:28.272594",
     "exception": false,
     "start_time": "2020-11-26T17:14:28.208601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054086,
     "end_time": "2020-11-26T17:14:28.379962",
     "exception": false,
     "start_time": "2020-11-26T17:14:28.325876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Restore from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:14:28.492370Z",
     "iopub.status.busy": "2020-11-26T17:14:28.491409Z",
     "iopub.status.idle": "2020-11-26T17:14:28.747197Z",
     "shell.execute_reply": "2020-11-26T17:14:28.746140Z"
    },
    "papermill": {
     "duration": 0.314331,
     "end_time": "2020-11-26T17:14:28.747313",
     "exception": false,
     "start_time": "2020-11-26T17:14:28.432982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f826c3f84d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:14:28.853147Z",
     "iopub.status.busy": "2020-11-26T17:14:28.852218Z",
     "iopub.status.idle": "2020-11-26T17:14:29.190792Z",
     "shell.execute_reply": "2020-11-26T17:14:29.192576Z"
    },
    "papermill": {
     "duration": 0.394459,
     "end_time": "2020-11-26T17:14:29.192801",
     "exception": false,
     "start_time": "2020-11-26T17:14:28.798342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> jag gillar att spela spel <end>\n",
      "Predicted translation: i like playing games . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Jag gillar att spela spel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 637.12323,
   "end_time": "2020-11-26T17:14:31.016417",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-26T17:03:53.893187",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
